"""Streamlit Data Analyst â€“ fully selfâ€‘contained app
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Features
- Reads API keys from **StreamlitÂ secrets** first, then environment vars
- Displays architecture & sequence diagrams (fails gracefully if missing)
- Upload CSV / Excel â†’ lightweight EDA (summary + basic chart)
- Optionally invokes a CrewAI pipeline to generate deeper insights
"""

from __future__ import annotations

# â”€â”€â”€ Standard Library â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import json
import os
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple

# â”€â”€â”€ Thirdâ€‘party â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from PIL import Image  # for safe image handling

# CrewAI stack
from crewai import Agent, Task, Crew, LLM

# â”€â”€â”€ Environment helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_key(var_name: str) -> str | None:
    """Return key from Streamlit secrets if present, else from env. """
    return st.secrets.get(var_name) if var_name in st.secrets else os.getenv(var_name)

# populate the variables CrewAI / OpenAI expect â€“ even if empty (prevents KeyErrors)
os.environ["OPENAI_API_KEY"]     = _get_key("OPENAI_API_KEY") or ""
os.environ["ANTHROPIC_API_KEY"] = _get_key("ANTHROPIC_API_KEY") or ""
os.environ["GOOGLE_API_KEY"]    = _get_key("GOOGLE_API_KEY")  or ""
os.environ["GROQ_API_KEY"]      = _get_key("GROQ_API_KEY")    or ""

# â”€â”€â”€ LLM options shown in the sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LLM_CONFIGS: Dict[str, Dict[str, List[str]]] = {
    "OpenAI":      {"models": ["gpt-3.5-turbo", "gpt-4o-mini", "gpt-4o"]},
    "Anthropic":   {"models": ["claude-3-sonnet-20240229", "claude-3-opus-20240229"]},
    "Groq":        {"models": ["Llama3-70B-8192", "Mixtral-8x22B"]},
}

# â”€â”€â”€ UI helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _safe_image(path: Path, caption: str):
    """Render an image if it exists; otherwise show a friendly warning."""
    if path.exists():
        st.image(path, caption=caption, use_column_width=True)
    else:
        st.info(f"âš ï¸Â Missing image: **{path.name}** â€“ add it to your repo or update `render_workflow_diagram()`. ")

def render_workflow_diagram() -> None:
    with st.expander("ğŸ“– System Workflow", expanded=False):
        img_dir = Path(__file__).parent / "images"
        _safe_image(img_dir / "data_analysis_architecture.png", "Highâ€‘level architecture")
        _safe_image(img_dir / "data_analysis_sequence_diagram.png", "Sequence diagram")

# â”€â”€â”€ Data utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _read_uploaded(file) -> pd.DataFrame:
    """Return a DataFrame from uploaded CSV or Excel file."""
    suffix = Path(file.name).suffix.lower()
    if suffix == ".csv":
        return pd.read_csv(file)
    elif suffix in {".xls", ".xlsx"}:
        return pd.read_excel(file)
    else:
        raise ValueError("Unsupported file type â€“ upload CSV or Excel")

def _basic_eda(df: pd.DataFrame):
    """Show shape, null counts, and descriptive stats inline."""
    st.subheader("ğŸ“ŠÂ Basic EDA")
    st.write("**Shape:**", df.shape)

    with st.expander("Null values by column"):
        st.write(df.isna().sum())

    with st.expander("Descriptive statistics"):
        st.write(df.describe())

    # example quick chart for numeric columns
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    if numeric_cols:
        st.subheader("Distribution of first numeric column")
        fig = px.histogram(df, x=numeric_cols[0])
        st.plotly_chart(fig, use_container_width=True)

# â”€â”€â”€ CrewAI pipeline (optional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _run_crewai_analysis(df: pd.DataFrame, provider: str, model: str) -> str:
    """Run a very simple CrewAI workflow and return the generated report."""
    # 1ï¸âƒ£  Set the LLM to use
    llm = LLM(provider=provider.lower(), model=model)

    # 2ï¸âƒ£  Define Agents
    analyst = Agent(
        role="Data Analyst",
        goal="Generate a concise but insightful analysis of the provided dataset",
        llm=llm,
        backstory="You are a seasoned data analyst who explains things clearly for stakeholders with varied technical backgrounds."
    )

    # 3ï¸âƒ£  Persist the dataset to a temporary CSV so the agent can "read" it
    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv", mode="w", newline="") as tmp:
        df.to_csv(tmp.name, index=False)
        dataset_path = tmp.name

    # 4ï¸âƒ£  Create Task and Crew
    task = Task(
        agent=analyst,
        description=(
            "Read the CSV located at '" + dataset_path + "' (it's small). "
            "Produce a JSON with keys: 'summary', 'interesting_findings', 'recommended_visuals'."
        ),
        expected_output="JSON"
    )
    crew = Crew(agents=[analyst], tasks=[task])

    # 5ï¸âƒ£  Execute
    result: Dict[str, str] = json.loads(crew.run())  # type: ignore[arg-type]
    return (
        "### ğŸ“Â AIâ€‘generated report\n" +
        result.get("summary", "") + "\n\n" +
        "**Interesting findings:** " + result.get("interesting_findings", "") + "\n\n" +
        "**Recommended visuals:**Â " + result.get("recommended_visuals", "")
    )

# â”€â”€â”€ MainÂ app â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    st.set_page_config(page_title="ğŸ“ˆÂ Dataâ€‘Analyst", layout="wide")
    st.title("ğŸ“ˆÂ Dataâ€‘Analyst â€“ LLMâ€‘powered exploratory tool")

    # Sidebar â€“ choose LLM provider & model
    with st.sidebar:
        st.header("ğŸ”‘Â LLM settings")
        provider = st.selectbox("Provider", list(LLM_CONFIGS.keys()))
        model = st.selectbox("Model", LLM_CONFIGS[provider]["models"])
        run_ai = st.checkbox("Run AI insights with CrewAI", value=False)
        st.markdown("---")
        st.markdown("### âš™ï¸Â App settings")
        st.info(
            "Add your API keys under **â‹® â†’ Settings â†’ Secrets**.\n"
            "Env vars will be used as fallback for local runs."
        )

    render_workflow_diagram()

    # File uploader
    uploaded = st.file_uploader("Upload CSV or Excel", type=["csv", "xls", "xlsx"])
    if not uploaded:
        st.warning("ğŸ‘†Â Upload a dataset to get started.")
        return

    df = _read_uploaded(uploaded)
    st.success("Dataset loaded successfully!")
    st.dataframe(df.head())

    # Basic EDA always shown
    _basic_eda(df)

    # Optional CrewAI analysis
    if run_ai:
        with st.spinner("Calling CrewAI â€“ this might take a minuteâ€¦"):
            report_md = _run_crewai_analysis(df, provider, model)
        st.markdown(report_md, unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    main()
